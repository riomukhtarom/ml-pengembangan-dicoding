{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bite6db8bd4905c4497a23eeb50e5c99a2b",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPML - Submission 2\n",
    "Dataset yang digunakan merupakan data histori harga saham AMAZON dari tahun 2006 hingga tahun 2017. Pada project ini data yang digunakan merupakan harga saham tertinggi pada hari itu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengimport dataset menggunakan pandas\n",
    "Dataset diimport kemudian ditampilkan 5 data terakhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               Open     High      Low    Close   Volume  Name\nDate                                                         \n2017-12-22  1172.08  1174.62  1167.83  1168.36  1585054  AMZN\n2017-12-26  1168.36  1178.32  1160.55  1176.76  2005187  AMZN\n2017-12-27  1179.91  1187.29  1175.61  1182.26  1867208  AMZN\n2017-12-28  1189.00  1190.10  1184.38  1186.10  1841676  AMZN\n2017-12-29  1182.35  1184.00  1167.50  1169.47  2688391  AMZN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Name</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-12-22</th>\n      <td>1172.08</td>\n      <td>1174.62</td>\n      <td>1167.83</td>\n      <td>1168.36</td>\n      <td>1585054</td>\n      <td>AMZN</td>\n    </tr>\n    <tr>\n      <th>2017-12-26</th>\n      <td>1168.36</td>\n      <td>1178.32</td>\n      <td>1160.55</td>\n      <td>1176.76</td>\n      <td>2005187</td>\n      <td>AMZN</td>\n    </tr>\n    <tr>\n      <th>2017-12-27</th>\n      <td>1179.91</td>\n      <td>1187.29</td>\n      <td>1175.61</td>\n      <td>1182.26</td>\n      <td>1867208</td>\n      <td>AMZN</td>\n    </tr>\n    <tr>\n      <th>2017-12-28</th>\n      <td>1189.00</td>\n      <td>1190.10</td>\n      <td>1184.38</td>\n      <td>1186.10</td>\n      <td>1841676</td>\n      <td>AMZN</td>\n    </tr>\n    <tr>\n      <th>2017-12-29</th>\n      <td>1182.35</td>\n      <td>1184.00</td>\n      <td>1167.50</td>\n      <td>1169.47</td>\n      <td>2688391</td>\n      <td>AMZN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('AMZN_2006-01-01_to_2018-01-01.csv', index_col='Date', parse_dates=['Date'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menampilkan deskripsi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              Open         High          Low        Close        Volume\ncount  3019.000000  3019.000000  3019.000000  3019.000000  3.019000e+03\nmean    299.335310   302.371163   296.037695   299.376231  5.931712e+06\nstd     280.120547   281.826442   277.927134   279.980161  5.122034e+06\nmin      26.090000    26.300000    25.760000    26.070000  9.864350e+05\n25%      81.175000    82.580000    79.725000    81.090000  3.137037e+06\n50%     205.330000   208.000000   202.100000   205.440000  4.724100e+06\n75%     375.570000   379.155000   373.000000   375.140000  7.135246e+06\nmax    1204.880000  1213.410000  1191.150000  1195.830000  1.044046e+08",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3019.000000</td>\n      <td>3019.000000</td>\n      <td>3019.000000</td>\n      <td>3019.000000</td>\n      <td>3.019000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>299.335310</td>\n      <td>302.371163</td>\n      <td>296.037695</td>\n      <td>299.376231</td>\n      <td>5.931712e+06</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>280.120547</td>\n      <td>281.826442</td>\n      <td>277.927134</td>\n      <td>279.980161</td>\n      <td>5.122034e+06</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>26.090000</td>\n      <td>26.300000</td>\n      <td>25.760000</td>\n      <td>26.070000</td>\n      <td>9.864350e+05</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>81.175000</td>\n      <td>82.580000</td>\n      <td>79.725000</td>\n      <td>81.090000</td>\n      <td>3.137037e+06</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>205.330000</td>\n      <td>208.000000</td>\n      <td>202.100000</td>\n      <td>205.440000</td>\n      <td>4.724100e+06</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>375.570000</td>\n      <td>379.155000</td>\n      <td>373.000000</td>\n      <td>375.140000</td>\n      <td>7.135246e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1204.880000</td>\n      <td>1213.410000</td>\n      <td>1191.150000</td>\n      <td>1195.830000</td>\n      <td>1.044046e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membagi data test dan dat train\n",
    "Data test yang digunakan dari tahun 2006 hingga tahun 2015 (10 tahun). Sedangkan data test yang digunakan dari tahun 2016 hingga tahun 2018 (3 tahun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high = df['High']\n",
    "high_train = df['High']['2006':'2014']\n",
    "high_test = df['High']['2015':'2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    3019.000000\nmean      302.371163\nstd       281.826442\nmin        26.300000\n25%        82.580000\n50%       208.000000\n75%       379.155000\nmax      1213.410000\nName: High, dtype: float64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "high.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_train.size , high_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menampilkan plot perubahan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1000x400 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "high_train.plot(subplots=True, figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buat fungsi untuk melakukan windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melakukan windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = windowed_dataset(high_train, window_size=250, batch_size=100, shuffle_buffer=1000)\n",
    "test_set = windowed_dataset(high_test, window_size=250, batch_size=100, shuffle_buffer=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arsitektur model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "ts_model = Sequential()\n",
    "ts_model.add(LSTM(100, return_sequences=True))\n",
    "ts_model.add(LSTM(200))\n",
    "ts_model.add(Dense(100, activation='relu'))\n",
    "ts_model.add(Dense(50, activation='relu'))\n",
    "ts_model.add(Dense(10, activation='relu'))\n",
    "ts_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengompile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "optimizer = SGD(lr=0.9200e-01, momentum=0.9)\n",
    "ts_model.compile(loss=Huber(), optimizer=optimizer, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melakukan fitting pada model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer sequential is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nEpoch 1/100\n21/21 [==============================] - 7s 344ms/step - loss: 171.0756 - mae: 172.3298\nEpoch 2/100\n21/21 [==============================] - 4s 187ms/step - loss: 141.1651 - mae: 141.9944\nEpoch 3/100\n21/21 [==============================] - 4s 187ms/step - loss: 123.1022 - mae: 123.7816\nEpoch 4/100\n21/21 [==============================] - 4s 184ms/step - loss: 109.0881 - mae: 109.7006\nEpoch 5/100\n21/21 [==============================] - 4s 185ms/step - loss: 98.6273 - mae: 99.2811\nEpoch 6/100\n21/21 [==============================] - 4s 186ms/step - loss: 91.9190 - mae: 92.5462\nEpoch 7/100\n21/21 [==============================] - 4s 185ms/step - loss: 89.2364 - mae: 89.9353\nEpoch 8/100\n21/21 [==============================] - 4s 186ms/step - loss: 88.3551 - mae: 88.7616\nEpoch 9/100\n21/21 [==============================] - 4s 186ms/step - loss: 87.3754 - mae: 88.1209\nEpoch 10/100\n21/21 [==============================] - 4s 189ms/step - loss: 86.9779 - mae: 87.4670\nEpoch 11/100\n21/21 [==============================] - 4s 185ms/step - loss: 86.2028 - mae: 86.9457\nEpoch 12/100\n21/21 [==============================] - 4s 186ms/step - loss: 85.8679 - mae: 86.3368\nEpoch 13/100\n21/21 [==============================] - 4s 185ms/step - loss: 85.2473 - mae: 85.7153\nEpoch 14/100\n21/21 [==============================] - 4s 187ms/step - loss: 84.5224 - mae: 85.1794\nEpoch 15/100\n21/21 [==============================] - 4s 189ms/step - loss: 84.1326 - mae: 84.6640\nEpoch 16/100\n21/21 [==============================] - 4s 191ms/step - loss: 83.5704 - mae: 84.2403\nEpoch 17/100\n21/21 [==============================] - 4s 205ms/step - loss: 83.3596 - mae: 83.9672\nEpoch 18/100\n21/21 [==============================] - 4s 186ms/step - loss: 83.0698 - mae: 83.7594\nEpoch 19/100\n21/21 [==============================] - 4s 188ms/step - loss: 83.0345 - mae: 83.6659\nEpoch 20/100\n21/21 [==============================] - 4s 205ms/step - loss: 83.0601 - mae: 83.5908\nEpoch 21/100\n21/21 [==============================] - 4s 208ms/step - loss: 82.8930 - mae: 83.5909\nEpoch 22/100\n21/21 [==============================] - 4s 203ms/step - loss: 83.0291 - mae: 83.6024\nEpoch 23/100\n21/21 [==============================] - 4s 190ms/step - loss: 83.0654 - mae: 83.5974\nEpoch 24/100\n21/21 [==============================] - 4s 206ms/step - loss: 82.9969 - mae: 83.5590\nEpoch 25/100\n21/21 [==============================] - 4s 188ms/step - loss: 82.8299 - mae: 83.5771\nEpoch 26/100\n21/21 [==============================] - 4s 206ms/step - loss: 83.0468 - mae: 83.5919\nEpoch 27/100\n21/21 [==============================] - 4s 207ms/step - loss: 83.0665 - mae: 83.5908\nEpoch 28/100\n21/21 [==============================] - 4s 207ms/step - loss: 82.8625 - mae: 83.6125\nEpoch 29/100\n21/21 [==============================] - 4s 206ms/step - loss: 82.9546 - mae: 83.6230\nEpoch 30/100\n21/21 [==============================] - 4s 210ms/step - loss: 83.0208 - mae: 83.5949\nEpoch 31/100\n21/21 [==============================] - 4s 205ms/step - loss: 82.8583 - mae: 83.5919\nEpoch 32/100\n21/21 [==============================] - 4s 200ms/step - loss: 83.0941 - mae: 83.6259\nEpoch 33/100\n21/21 [==============================] - 4s 207ms/step - loss: 82.9401 - mae: 83.6247\nEpoch 34/100\n21/21 [==============================] - 4s 203ms/step - loss: 83.2811 - mae: 83.6585\nEpoch 35/100\n21/21 [==============================] - 4s 193ms/step - loss: 83.0328 - mae: 83.6543\nEpoch 36/100\n21/21 [==============================] - 4s 208ms/step - loss: 83.1406 - mae: 83.6216\nEpoch 37/100\n21/21 [==============================] - 4s 206ms/step - loss: 82.9115 - mae: 83.6464\nEpoch 38/100\n21/21 [==============================] - 4s 209ms/step - loss: 83.0337 - mae: 83.6123\nEpoch 39/100\n21/21 [==============================] - 4s 205ms/step - loss: 83.1199 - mae: 83.6319\nEpoch 40/100\n21/21 [==============================] - 4s 205ms/step - loss: 83.0167 - mae: 83.6386\nEpoch 41/100\n21/21 [==============================] - 4s 208ms/step - loss: 83.0919 - mae: 83.6372\nEpoch 42/100\n21/21 [==============================] - 4s 208ms/step - loss: 83.1497 - mae: 83.6356\nEpoch 43/100\n21/21 [==============================] - 4s 208ms/step - loss: 82.8010 - mae: 83.6145\nEpoch 44/100\n21/21 [==============================] - 4s 207ms/step - loss: 83.0848 - mae: 83.6401\nEpoch 45/100\n21/21 [==============================] - 4s 210ms/step - loss: 82.8864 - mae: 83.6412\nEpoch 46/100\n21/21 [==============================] - 4s 206ms/step - loss: 82.9262 - mae: 83.6257\nEpoch 47/100\n21/21 [==============================] - 4s 204ms/step - loss: 82.8594 - mae: 83.6027\nEpoch 48/100\n21/21 [==============================] - 4s 207ms/step - loss: 82.9022 - mae: 83.6243\nEpoch 49/100\n21/21 [==============================] - 4s 206ms/step - loss: 83.0654 - mae: 83.6127\nEpoch 50/100\n21/21 [==============================] - 4s 209ms/step - loss: 83.0468 - mae: 83.6227\nEpoch 51/100\n21/21 [==============================] - 4s 206ms/step - loss: 83.0659 - mae: 83.6476\nEpoch 52/100\n21/21 [==============================] - 4s 209ms/step - loss: 83.0225 - mae: 83.6111\nEpoch 53/100\n21/21 [==============================] - 4s 206ms/step - loss: 82.7563 - mae: 83.6144\nEpoch 54/100\n21/21 [==============================] - 4s 206ms/step - loss: 82.9254 - mae: 83.6261\nEpoch 55/100\n21/21 [==============================] - 4s 206ms/step - loss: 82.9914 - mae: 83.6357\nEpoch 56/100\n21/21 [==============================] - 5s 219ms/step - loss: 82.7724 - mae: 83.6454\nEpoch 57/100\n21/21 [==============================] - 4s 213ms/step - loss: 83.0926 - mae: 83.6177\nEpoch 58/100\n21/21 [==============================] - 4s 210ms/step - loss: 82.9979 - mae: 83.6286\nEpoch 59/100\n21/21 [==============================] - 4s 210ms/step - loss: 82.7897 - mae: 83.6009\nEpoch 60/100\n21/21 [==============================] - 4s 207ms/step - loss: 82.9561 - mae: 83.6240\nEpoch 61/100\n21/21 [==============================] - 4s 208ms/step - loss: 83.0921 - mae: 83.6384\nEpoch 62/100\n21/21 [==============================] - 4s 209ms/step - loss: 82.8756 - mae: 83.6369\nEpoch 63/100\n21/21 [==============================] - 4s 210ms/step - loss: 83.0663 - mae: 83.6465\nEpoch 64/100\n21/21 [==============================] - 5s 235ms/step - loss: 83.0570 - mae: 83.6545\nEpoch 65/100\n21/21 [==============================] - 4s 209ms/step - loss: 83.0727 - mae: 83.6512\nEpoch 66/100\n21/21 [==============================] - 4s 209ms/step - loss: 83.0737 - mae: 83.6208\nEpoch 67/100\n21/21 [==============================] - 4s 213ms/step - loss: 82.9817 - mae: 83.6705\nEpoch 68/100\n21/21 [==============================] - 4s 207ms/step - loss: 83.1658 - mae: 83.6530\nEpoch 69/100\n21/21 [==============================] - 4s 208ms/step - loss: 82.9647 - mae: 83.6529\nEpoch 70/100\n21/21 [==============================] - 4s 208ms/step - loss: 83.0127 - mae: 83.6566\nEpoch 71/100\n21/21 [==============================] - 4s 210ms/step - loss: 83.2045 - mae: 83.6511\nEpoch 72/100\n21/21 [==============================] - 4s 212ms/step - loss: 82.8931 - mae: 83.6608\nEpoch 73/100\n21/21 [==============================] - 4s 210ms/step - loss: 83.1104 - mae: 83.6271\nEpoch 74/100\n21/21 [==============================] - 4s 206ms/step - loss: 83.1494 - mae: 83.6742\nEpoch 75/100\n21/21 [==============================] - 4s 208ms/step - loss: 82.9964 - mae: 83.6327\nEpoch 76/100\n21/21 [==============================] - 4s 208ms/step - loss: 82.6077 - mae: 83.6451\nEpoch 77/100\n21/21 [==============================] - 4s 210ms/step - loss: 82.8982 - mae: 83.6224\nEpoch 78/100\n21/21 [==============================] - 4s 211ms/step - loss: 83.0026 - mae: 83.5904\nEpoch 79/100\n21/21 [==============================] - 4s 213ms/step - loss: 82.8649 - mae: 83.6248\nEpoch 80/100\n21/21 [==============================] - 4s 213ms/step - loss: 83.2811 - mae: 83.6456\nEpoch 81/100\n21/21 [==============================] - 4s 209ms/step - loss: 83.1260 - mae: 83.6718\nEpoch 82/100\n21/21 [==============================] - 4s 207ms/step - loss: 83.0675 - mae: 83.6701\nEpoch 83/100\n21/21 [==============================] - 4s 212ms/step - loss: 83.1194 - mae: 83.6763\nEpoch 84/100\n21/21 [==============================] - 4s 209ms/step - loss: 82.9901 - mae: 83.6468\nEpoch 85/100\n21/21 [==============================] - 4s 213ms/step - loss: 82.7818 - mae: 83.6223\nEpoch 86/100\n21/21 [==============================] - 4s 210ms/step - loss: 83.1130 - mae: 83.6316\nEpoch 87/100\n21/21 [==============================] - 4s 211ms/step - loss: 83.2539 - mae: 83.7290\nEpoch 88/100\n21/21 [==============================] - 4s 209ms/step - loss: 82.9983 - mae: 83.6497\nEpoch 89/100\n21/21 [==============================] - 4s 210ms/step - loss: 82.8503 - mae: 83.6800\nEpoch 90/100\n21/21 [==============================] - 4s 210ms/step - loss: 82.9145 - mae: 83.6325\nEpoch 91/100\n21/21 [==============================] - 4s 212ms/step - loss: 83.0498 - mae: 83.6348\nEpoch 92/100\n21/21 [==============================] - 4s 210ms/step - loss: 83.2599 - mae: 83.6510\nEpoch 93/100\n21/21 [==============================] - 4s 212ms/step - loss: 82.9947 - mae: 83.6466\nEpoch 94/100\n21/21 [==============================] - 4s 210ms/step - loss: 82.9972 - mae: 83.6485\nEpoch 95/100\n21/21 [==============================] - 4s 208ms/step - loss: 82.9386 - mae: 83.6424\nEpoch 96/100\n21/21 [==============================] - 4s 207ms/step - loss: 83.0210 - mae: 83.5951\nEpoch 97/100\n21/21 [==============================] - 4s 206ms/step - loss: 83.1278 - mae: 83.6751\nEpoch 98/100\n21/21 [==============================] - 4s 208ms/step - loss: 82.9114 - mae: 83.6367\nEpoch 99/100\n21/21 [==============================] - 4s 209ms/step - loss: 82.9031 - mae: 83.6026\nEpoch 100/100\n21/21 [==============================] - 5s 220ms/step - loss: 82.6732 - mae: 83.6010\n"
    }
   ],
   "source": [
    "epochs_num = 100\n",
    "ts_history = ts_model.fit(train_set, epochs=epochs_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafik perubahan mae terhadap jumlah epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mae = ts_history.history['mae']\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "plt.plot(epochs, mae, 'blue', label='mae')\n",
    "plt.title('Training mae')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}