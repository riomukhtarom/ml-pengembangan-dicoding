{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bite6db8bd4905c4497a23eeb50e5c99a2b",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPML - Submission 1\n",
    "Dataset yang dgunakan adalah data Sentiment positif dan negatif dari twitter.\n",
    "Dataset ini terdiri dari 1600000 data.\n",
    "Terdapat 6 Variabel pada dataset namun pada submission ini hanya menggunakan 2 variabel yaitu Sentiment(Positif atau Negatif) dan isi twitter.\n",
    "Pada project ini akan diklasifikasikan isi twitter yang bersentimen positif atau negatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengimport dataset menggunakan pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sentiment.csv', header=None, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menampilkan 5 data terakhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         0           1                             2         3  \\\n1599995  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n1599996  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n1599997  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n1599998  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n1599999  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n\n                       4                                                  5  \n1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1599995</th>\n      <td>4</td>\n      <td>2193601966</td>\n      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>AmandaMarie1028</td>\n      <td>Just woke up. Having no school is the best fee...</td>\n    </tr>\n    <tr>\n      <th>1599996</th>\n      <td>4</td>\n      <td>2193601969</td>\n      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>TheWDBoards</td>\n      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n    </tr>\n    <tr>\n      <th>1599997</th>\n      <td>4</td>\n      <td>2193601991</td>\n      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>bpbabe</td>\n      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n    </tr>\n    <tr>\n      <th>1599998</th>\n      <td>4</td>\n      <td>2193602064</td>\n      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>tinydiamondz</td>\n      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n    </tr>\n    <tr>\n      <th>1599999</th>\n      <td>4</td>\n      <td>2193602129</td>\n      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>RyanTrevMorris</td>\n      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menghapus Kolom yang tidak digunakan\n",
    "Pada project ini hanya digunakan kolom 0 (sentimen) dan 5 (isi twitter).\n",
    "Kolom 1,2,3,4 dihapus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengganti isi kolom 0(sentimen)\n",
    "Nilai pada kolom 0 yaitu 0 (untuk sentimen negatif) dan 4 (untuk sentimen positif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].replace([0,4], [0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membagi data menjadi data training dan data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df[5].values\n",
    "sentiment = df[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweets, sentiment, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melakukan Tokenizing dan Padding Terhadap data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='-')\n",
    "tokenizer.fit_on_texts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train = tokenizer.texts_to_sequences(x_train)\n",
    "seq_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "pad_train = pad_sequences(seq_train)\n",
    "pad_test = pad_sequences(seq_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Arsitektur Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 32)          320000    \n_________________________________________________________________\nlstm (LSTM)                  (None, 64)                24832     \n_________________________________________________________________\ndense (Dense)                (None, 512)               33280     \n_________________________________________________________________\ndense_1 (Dense)              (None, 1024)              525312    \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndense_3 (Dense)              (None, 64)                32832     \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 1,461,121\nTrainable params: 1,461,121\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "nlp_model = Sequential()\n",
    "nlp_model.add(Embedding(input_dim=10000, output_dim=32))\n",
    "nlp_model.add(LSTM(64))\n",
    "nlp_model.add(Dense(512, activation='relu'))\n",
    "nlp_model.add(Dense(1024, activation='relu'))\n",
    "nlp_model.add(Dense(512, activation='relu'))\n",
    "nlp_model.add(Dense(64, activation='relu'))\n",
    "nlp_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "nlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melakukan compile terhadap model\n",
    "Model arsitektur yang telah dibuat dilakukan compile menggunakan loss function binary_crossntropy (karena classnya hanya 2) dan optimizer adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melakukan fitting\n",
    "Melakukan fitting terhadap model menggunakan data training dan divalidasi menggunakan data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 1280000 samples, validate on 320000 samples\nEpoch 1/10\n1280000/1280000 [==============================] - 167s 131us/sample - loss: 0.4458 - accuracy: 0.7892 - val_loss: 0.4168 - val_accuracy: 0.8061\nEpoch 2/10\n1280000/1280000 [==============================] - 165s 129us/sample - loss: 0.4058 - accuracy: 0.8131 - val_loss: 0.4013 - val_accuracy: 0.8160\nEpoch 3/10\n1280000/1280000 [==============================] - 166s 130us/sample - loss: 0.3874 - accuracy: 0.8234 - val_loss: 0.3963 - val_accuracy: 0.8205\nEpoch 4/10\n1280000/1280000 [==============================] - 167s 130us/sample - loss: 0.3758 - accuracy: 0.8298 - val_loss: 0.3919 - val_accuracy: 0.8215\nEpoch 5/10\n1280000/1280000 [==============================] - 166s 130us/sample - loss: 0.3672 - accuracy: 0.8343 - val_loss: 0.3923 - val_accuracy: 0.8211\nEpoch 6/10\n1280000/1280000 [==============================] - 167s 131us/sample - loss: 0.3593 - accuracy: 0.8388 - val_loss: 0.3938 - val_accuracy: 0.8217\nEpoch 7/10\n1280000/1280000 [==============================] - 167s 130us/sample - loss: 0.3519 - accuracy: 0.8429 - val_loss: 0.3952 - val_accuracy: 0.8218\nEpoch 8/10\n1280000/1280000 [==============================] - 166s 130us/sample - loss: 0.3441 - accuracy: 0.8467 - val_loss: 0.3975 - val_accuracy: 0.8220\nEpoch 9/10\n1280000/1280000 [==============================] - 165s 129us/sample - loss: 0.3365 - accuracy: 0.8508 - val_loss: 0.4021 - val_accuracy: 0.8206\nEpoch 10/10\n1280000/1280000 [==============================] - 166s 129us/sample - loss: 0.3290 - accuracy: 0.8548 - val_loss: 0.4073 - val_accuracy: 0.8195\n"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "nlp_model_history = nlp_model.fit(pad_train, y_train, epochs=num_epochs, validation_data=(pad_test, y_test), batch_size=2048, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafik perubahan akurasi terhadap jumlah epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = nlp_model_history.history['accuracy']\n",
    "val_acc = nlp_model_history.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'blue', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'black', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}